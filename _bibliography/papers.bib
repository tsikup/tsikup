---
---

@inproceedings{Span1912:Renyi,
  abbr       = {Conference},
  author     = {Constantinos Spanakis and Emmanuel Mathioudakis and Nikos Kampanis and
Nikos Tsiknakis and Kostas Marias},
  title      = {Renyi divergence and non-deterministic subsampling in Rigid Image
Registration},
  booktitle  = {IEEE International Conference on Imaging Systems and Techniques (IST)},
  address    = {Abu Dhabi, United Arab Emirates},
  days       = 7,
  month      = dec,
  year       = 2019,
  doi        = {https://doi.org/10.1109/IST48021.2019.9010237},
  simple_doi = {10.1109/IST48021.2019.9010237},
  keywords   = {Renyi divergence; Renyi Entropy; Rigid Image Registration; Subsampling;
Mutual Information},
  abstract   = {The successful application and reported robustness of Mutual Information
both in rigid and nonrigid image registration over the last decades gave
rise to an ongoing research on other information based similarity metrics
emanating from Renyi Divergence. To the best of our knowledge however, this
is the first paper studying the effects of Renyi parameter in combination
with a subsampling factor in image registration accuracy. To this end, a
series of experiments are presented with respect to the effect of Renyi's
parameter and the subsampling factor in registration accuracy. Our results
show that the increase of the Renyi parameter and the percentage of the
pixels used leads, on average, to the reduction of the registration error.}
}

@article{tsiknakis2020covid,
  abbr       = {Journal},
  author     = {Nikos Tsiknakis and Eleftherios Trivizakis and Evangelia E. Vassalou and Georgios Z. Papadakis and Demetrios A. Spandidos and Aristidis Tsatsakis and Jose Sánchez‑García and Rafael López‑González and Nikolaos Papanikolaou and Apostolos H. Karantanas and Kostas Marias },
  title      = {Interpretable artificial intelligence framework for COVID‑19 screening on chest X‑rays},
  journal    = {Experimental and Therapeutic Medicine},
  publisher  = {Spandidos Publications},
  days       = 27,
  month      = may,
  year       = 2020,
  doi        = {https://doi.org/10.3892/etm.2020.8797},
  simple_doi = {10.3892/etm.2020.8797},
  code       = {https://github.com/tsikup/covid19-xray-cnn},
  pdf        = {Interpretable_artificial_intelligence_framework_for_COVID_19_screening_on_chest_X_rays.pdf},
  keywords   = {COVID‐19, chest X‐rays, interpretable artificial intelligence, transfer learning},
  abstract   = {COVID-19 has led to an unprecedented healthcare crisis with millions of infected people across the globe often pushing infrastructures, healthcare workers and entire economies beyond their limits. The scarcity of testing kits, even in developed countries, has led to extensive research efforts towards alternative solutions with high sensitivity. Chest radiological imaging paired with artificial intelligence (AI) can offer significant advantages in diagnosis of novel coronavirus infected patients. To this end, transfer learning techniques are used for overcoming the limitations emanating from the lack of relevant big datasets, enabling specialized models to converge on limited data, as in the case of X‑rays of COVID‑19 patients. In this study, we present an interpretable AI framework assessed by expert radiologists on the basis on how well the attention maps focus on the diagnostically‑relevant image regions. The proposed transfer learning methodology achieves an overall area under the curve of 1 for a binary classification problem across a 5‑fold training/testing dataset.},
  selected   = {true}
}

@article{trivizakis2020advancing,
  abbr       = {Journal},
  title      = {Advancing COVID-19 differentiation with a robust preprocessing and integration of multi-institutional open-repository computer tomography datasets for deep learning analysis},
  author     = {Trivizakis, Eleftherios and Tsiknakis, Nikos and Vassalou, Evangelia E and Papadakis, Georgios Z and Spandidos, Demetrios A and Sarigiannis, Dimosthenis and Tsatsakis, Aristidis and Papanikolaou, Nikolaos and Karantanas, Apostolos H and Marias, Kostas},
  journal    = {Experimental and Therapeutic Medicine},
  publisher  = {Spandidos Publications},
  volume     = {20},
  number     = {5},
  year       = {2020},
  days       = 11,
  month      = sep,
  code       = {https://github.com/trivizakis/ct-covid-analysis},
  pdf        = {Advancing_COVID_19_differentiation_with_a_robust_preprocessing_and_integration_of_multi_institutional_open_repository_computer_tomography_datasets_for_deep_learning_analysis.pdf},
  doi        = {https://doi.org/10.3892/etm.2020.9210},
  simple_doi = {10.3892/etm.2020.9210},
  abstract   = {The coronavirus pandemic and its unprecedented consequences globally has spurred the interest of the artificial intelligence research community. A plethora of published studies have investigated the role of imaging such as chest X‑rays and computer tomography in coronavirus disease 2019 (COVID‑19) automated diagnosis. Οpen repositories of medical imaging data can play a significant role by promoting cooperation among institutes in a world‑wide scale. However, they may induce limitations related to variable data quality and intrinsic differences due to the wide variety of scanner vendors and imaging parameters. In this study, a state‑of‑the‑art custom U‑Net model is presented with a dice similarity coefficient performance of 99.6% along with a transfer learning VGG‑19 based model for COVID‑19 versus pneumonia differentiation exhibiting an area under curve of 96.1%. The above was significantly improved over the baseline model trained with no segmentation in selected tomographic slices of the same dataset. The presented study highlights the importance of a robust preprocessing protocol for image analysis within a heterogeneous imaging dataset and assesses the potential diagnostic value of the presented COVID‑19 model by comparing its performance to the state of the art.}
}

@article{deeptsiknakis2021,
  abbr       = {Journal},
  title      = {Deep Learning for Diabetic Retinopathy Detection and Classification Based on Fundus Images: A Review},
  journal    = {Computers in Biology and Medicine},
  publisher  = {Elsevier},
  pages      = {104599},
  year       = {2021},
  issn       = {0010-4825},
  pdf        = {Tsiknakis - Deep learning for diabetic retinopathy detection and classification based on fundus images: A review.pdf},
  doi        = {https://doi.org/10.1016/j.compbiomed.2021.104599},
  simple_doi = {10.1016/j.compbiomed.2021.104599},
  url        = {https://www.sciencedirect.com/science/article/pii/S0010482521003930},
  author     = {Nikos Tsiknakis and Dimitris Theodoropoulos and Georgios Manikis and Emmanouil Ktistakis and Ourania Boutsora and Alexa Berto and Fabio Scarpa and Alberto Scarpa and Dimitrios I. Fotiadis and Kostas Marias},
  keywords   = {artificial intelligence, classification, deep learning, detection, diabetic retinopathy, fundus, retina, review, segmentation},
  abstract   = {Diabetic Retinopathy is a retina disease caused by diabetes mellitus and it is the leading cause of blindness globally. Early detection and treatment are necessary in order to delay or avoid vision deterioration and vision loss. To that end, many artificial-intelligence-powered methods have been proposed by the research community for the detection and classification of diabetic retinopathy on fundus retina images. This review article provides a thorough analysis of the use of deep learning methods at the various steps of the diabetic retinopathy detection pipeline based on fundus images. We discuss several aspects of that pipeline, ranging from the datasets that are widely used by the research community, the preprocessing techniques employed and how these accelerate and improve the models’ performance, to the development of such deep learning models for the diagnosis and grading of the disease as well as the localization of the disease’s lesions. We also discuss certain models that have been applied in real clinical settings. Finally, we conclude with some important insights and provide future research directions.},
  selected   = {true}
}